{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNvBBBhXQzi3"
      },
      "source": [
        "# Preliminary exploration notebook\n",
        "\n",
        "This notebook contains the following:\n",
        "* Data loading and brief visualization\n",
        "* Logistic regression\n",
        "* CNN training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIyROfMHQ8HS",
        "outputId": "9fbe2cea-a183-4f3d-8736-24e912a06f94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-PIXpkD_W4Uu",
        "outputId": "e71c546d-d26e-451b-b277-44f3c6ab0305"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nassumes the following structure:\\n- MicrosoftSnakeAlgorithmProject\\n- Snakes-or-No-Snakes\\n    - *.ipynb (you are here)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import os # work with system    \n",
        "import cv2 # work with images\n",
        "import numpy as np # arrays and numerical analysis  \n",
        "import matplotlib.pyplot as plt # for data plots\n",
        "\n",
        "import sklearn.linear_model # linear models\n",
        "from sklearn.model_selection import train_test_split # data splitting\n",
        "from sklearn import metrics # model evaluation\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "os.chdir(\"drive/Shareddrives/Capstone 2023/Data/MicrosoftSnakeAlgorithmProject\")\n",
        "\n",
        "\n",
        "### set working directory in data folder\n",
        "\"\"\"\n",
        "assumes the following structure:\n",
        "- MicrosoftSnakeAlgorithmProject\n",
        "- Snakes-or-No-Snakes\n",
        "    - *.ipynb (you are here)\n",
        "\"\"\"\n",
        "# os.chdir(\"../MicrosoftSnakeAlgorithmProject\")\n",
        "# os.chdir(\"../subset\") # small proof of concept subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9EvY-CVKVb2",
        "outputId": "ea599915-8741-4edd-bed8-65e3f3f4f4a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MicrosoftSnakeAlgorithmProject/Snake_Images/FL_Snakes/WF8/IMG_7087.JPG\n",
            "23275\n"
          ]
        }
      ],
      "source": [
        "counter = 0 # if desired to break loop\n",
        "\n",
        "# labels and filenames should match since they are appended in order\n",
        "filenames = []\n",
        "labels = []\n",
        "\n",
        "# one image does not open properly\n",
        "empty_img = \"MicrosoftSnakeAlgorithmProject/Snake_Images/FL_Snakes/WF8/IMG_7087.JPG\"\n",
        "# walk through all directories and files in current working directory\n",
        "for root, dir, files in os.walk(os.getcwd()):\n",
        "    \n",
        "    for jpg in files:\n",
        "        if empty_img in os.path.join(root, jpg):\n",
        "          print(empty_img)\n",
        "          continue\n",
        "\n",
        "        # if jpg file, then keep filename\n",
        "        if \".JPG\" in jpg:\n",
        "            filenames.append(os.path.join(root, jpg))\n",
        "\n",
        "        if \"Empty\" in root:\n",
        "          labels.append(0)\n",
        "        elif \"Snake\" in root:\n",
        "          labels.append(1)\n",
        "            \n",
        "    counter += 1\n",
        "    # if counter > 10000: break\n",
        "  \n",
        "print(len(filenames))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filenames_arr = np.array(filenames)\n",
        "labels_arr = np.array(labels)\n",
        "\n",
        "# split data: train is 1-test_size and test is test_size*leftover\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    filenames_arr, labels_arr, test_size = 0.2, stratify = labels_arr, shuffle = True, random_state = 27)\n",
        "\n",
        "x_val, x_test, y_val, y_test = train_test_split(\n",
        "    x_test, y_test, test_size = 0.75, stratify = y_test, shuffle = True, random_state = 27)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnvJaoQGwUKZ",
        "outputId": "0d9c78a6-8a0b-438f-e357-09d06b2574af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18620,)\n",
            "(1163,)\n",
            "(3492,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class data_generator(keras.utils.Sequence) :\n",
        "  \n",
        "  def __init__(self, image_filenames, labels, batch_size) :\n",
        "    self.image_filenames = image_filenames\n",
        "    self.labels = labels\n",
        "    self.batch_size = batch_size\n",
        "    \n",
        "    \n",
        "  def __len__(self) :\n",
        "    return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(int)\n",
        "  \n",
        "  \n",
        "  def __getitem__(self, idx) :\n",
        "    batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "\n",
        "    x_list = [cv2.resize(cv2.imread(file_name, cv2.IMREAD_GRAYSCALE), (512, 384), interpolation = cv2.INTER_NEAREST) for file_name in batch_x]\n",
        "    x_arr = np.array(x_list)\n",
        "    x_arr_reshaped = x_arr.reshape([x_arr.shape[0], x_arr.shape[1], x_arr.shape[2], 1])\n",
        "    y_arr = np.array(batch_y)\n",
        "    y_arr_reshaped = y_arr.reshape([x_arr_reshaped.shape[0], 1])\n",
        "\n",
        "    return x_arr_reshaped, y_arr_reshaped"
      ],
      "metadata": {
        "id": "6YkWuF12xLP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "my_training_batch_generator = data_generator(x_train, y_train, batch_size)\n",
        "my_validation_batch_generator = data_generator(x_val, y_val, batch_size)\n",
        "my_test_batch_generator = data_generator(x_test, y_test, batch_size)"
      ],
      "metadata": {
        "id": "QUQ4KIF20Ncy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create model \n",
        "def build_model():\n",
        "\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(384, 512, 1)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(10))\n",
        "\n",
        "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate=1e-2,\n",
        "        decay_steps=10000,\n",
        "        decay_rate=0.9)\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer = optimizer, loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "I2rsHpz40FMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "cnn_model = build_model()"
      ],
      "metadata": {
        "id": "2TeCVESl0Kou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqn7xDxKUkEg",
        "outputId": "c0911f99-d971-43a6-ea71-187e03b4ac8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 382, 510, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 191, 255, 32)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 189, 253, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 94, 126, 64)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 92, 124, 64)       36928     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 730112)            0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                46727232  \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 46,783,626\n",
            "Trainable params: 46,783,626\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_fit = cnn_model.fit(\n",
        "    my_training_batch_generator,\n",
        "    steps_per_epoch = int(x_train.shape[0] // batch_size),\n",
        "    epochs = 3,\n",
        "    verbose = 1,\n",
        "    validation_data = my_validation_batch_generator,\n",
        "    validation_steps = int(x_val.shape[0] // batch_size)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7n3LFWNX0oJ2",
        "outputId": "cd50c9c6-4a12-4ba0-f4a7-c247417cd750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "581/581 [==============================] - 9198s 16s/step - loss: 6.4309 - accuracy: 0.8525 - val_loss: 0.3080 - val_accuracy: 0.9071\n",
            "Epoch 2/3\n",
            "581/581 [==============================] - 8785s 15s/step - loss: 0.0680 - accuracy: 0.8248 - val_loss: 0.0179 - val_accuracy: 0.8194\n",
            "Epoch 3/3\n",
            "208/581 [=========>....................] - ETA: 1:31:42 - loss: 0.0144 - accuracy: 0.8140"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_predict = cnn_model.predict(\n",
        "    my_test_batch_generator,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkw76jZoDjyN",
        "outputId": "203dc840-87a1-49c4-b127-5f09eab7f703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-4fb8d3b79176>:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110/110 [==============================] - 434s 4s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get class predictions\n",
        "predictions_cnn = np.argmax(model_predict, axis = -1) \n",
        "print(predictions_cnn.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHhm9V2j78V0",
        "outputId": "d0a5e27d-0577-43f4-bd1f-b47c6eb6ffc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3492,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot confusion matrix\n",
        "metrics.ConfusionMatrixDisplay.from_predictions(y_test, predictions_cnn, cmap = \"GnBu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "CoTUxBArKjTf",
        "outputId": "1ade00a8-d8e9-4b01-e038-4e874ba7e702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f5ce53e47f0>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### model evaluation metrics \n",
        "\n",
        "# (true positive + true negative)/total\n",
        "accuracy = sklearn.metrics.accuracy_score(y_test, predictions_cnn)\n",
        "print(accuracy)\n",
        "\n",
        "# true positive/(true positive + false positive)\n",
        "precision = sklearn.metrics.precision_score(y_test, predictions_cnn)\n",
        "print(precision)\n",
        "\n",
        "# true positive/(true positive + false negative)\n",
        "sensitivity = sklearn.metrics.recall_score(y_test, predictions_cnn)\n",
        "print(sensitivity)\n",
        "\n",
        "# true negative/(true negative + false positive)\n",
        "specificity = sklearn.metrics.recall_score(y_test, predictions_cnn, pos_label = 0)\n",
        "print(specificity)\n",
        "\n",
        "# 2 * (precision*recall)/(precision+recall)\n",
        "f1_score = 2*(precision*sensitivity)/(precision+sensitivity)\n",
        "print(f1_score)\n",
        "\n",
        "# no false positives means precision and specificity will be 100%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW4daMTuKnSX",
        "outputId": "083036ef-ee5e-45f9-9ca1-4dc6b51e1584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9226804123711341\n",
            "0.9972451790633609\n",
            "0.5736925515055468\n",
            "0.999650471862985\n",
            "0.7283702213279678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot accuracy across epochs\n",
        "plt.plot(cnn_fit.history['accuracy'], label='accuracy')\n",
        "plt.plot(cnn_fit.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# plot accuracy across epochs\n",
        "plt.plot(cnn_fit.history['accuracy'], label='accuracy')\n",
        "plt.plot(cnn_fit.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# test_loss, test_acc = cnn_model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "T39EubL9LCQd",
        "outputId": "40d38410-0630-4192-d14e-15253a701750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f5ce537e3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # save model\n",
        "# cnn_model.save('../Snakes-or-No-Snakes/cnn_alldata_1e')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IScJl10KsS-",
        "outputId": "32a746c2-bf1d-44ad-ee6e-a1bd2ac875bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Below is original code, above is batched version"
      ],
      "metadata": {
        "id": "vwI3rWULyxh_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSVldCznKYgC",
        "outputId": "f6bb0725-45dc-468d-da59-f166e876f619"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "3500\n",
            "3600\n",
            "3700\n",
            "3800\n",
            "3900\n",
            "4000\n",
            "4100\n",
            "4200\n",
            "4300\n",
            "4400\n",
            "4500\n",
            "4600\n",
            "4700\n",
            "4800\n",
            "4900\n",
            "5000\n",
            "5100\n",
            "5200\n",
            "5300\n",
            "5400\n",
            "5500\n",
            "5600\n",
            "5700\n",
            "5800\n",
            "5900\n",
            "6000\n",
            "6100\n",
            "6200\n",
            "6300\n",
            "6400\n",
            "6500\n",
            "6600\n",
            "6700\n",
            "6800\n",
            "6900\n",
            "7000\n",
            "7100\n",
            "7200\n",
            "7300\n",
            "7400\n",
            "7500\n",
            "7600\n",
            "7700\n",
            "7800\n",
            "7900\n",
            "8000\n",
            "8100\n",
            "8200\n",
            "8300\n",
            "8400\n",
            "8500\n",
            "8600\n",
            "8700\n",
            "8800\n",
            "8900\n",
            "9000\n",
            "9100\n",
            "9200\n",
            "9300\n",
            "9400\n",
            "9500\n",
            "9600\n",
            "9700\n",
            "9800\n",
            "9900\n",
            "10000\n",
            "10100\n",
            "10200\n",
            "10300\n",
            "10400\n",
            "10500\n",
            "10600\n",
            "10700\n",
            "10800\n",
            "10900\n",
            "11000\n",
            "11100\n",
            "11200\n",
            "11300\n",
            "11400\n",
            "11500\n",
            "11600\n",
            "11700\n",
            "11800\n",
            "11900\n",
            "12000\n",
            "12100\n",
            "12200\n",
            "12300\n",
            "12400\n",
            "12500\n",
            "12600\n",
            "12700\n",
            "12800\n",
            "12900\n",
            "13000\n",
            "13100\n",
            "13200\n",
            "13300\n",
            "13400\n",
            "13500\n",
            "13600\n",
            "13700\n",
            "13800\n",
            "13900\n",
            "14000\n",
            "14100\n",
            "14200\n",
            "14300\n",
            "14400\n",
            "14500\n",
            "14600\n",
            "14700\n",
            "14800\n",
            "14900\n",
            "15000\n",
            "15100\n",
            "15200\n",
            "15300\n",
            "15400\n",
            "15500\n",
            "15600\n",
            "15700\n",
            "15800\n",
            "15900\n",
            "16000\n",
            "16100\n",
            "16200\n",
            "16300\n",
            "16400\n",
            "16500\n",
            "16600\n",
            "16700\n",
            "16800\n",
            "16900\n",
            "17000\n",
            "17100\n",
            "17200\n",
            "17300\n",
            "17400\n",
            "17500\n",
            "17600\n",
            "17700\n",
            "17800\n",
            "17900\n",
            "18000\n",
            "18100\n",
            "18200\n",
            "18300\n",
            "18400\n",
            "18500\n",
            "18600\n",
            "18700\n",
            "18800\n",
            "18900\n",
            "19000\n",
            "19100\n",
            "19200\n",
            "19300\n",
            "19400\n",
            "19500\n",
            "19600\n",
            "19700\n",
            "19800\n",
            "19900\n",
            "20000\n",
            "20100\n",
            "20200\n",
            "20300\n",
            "20400\n",
            "20500\n",
            "20600\n",
            "20700\n",
            "20800\n",
            "20900\n",
            "21000\n",
            "21100\n",
            "21200\n",
            "21300\n",
            "21400\n",
            "21500\n",
            "21600\n",
            "21700\n",
            "21800\n",
            "21900\n",
            "22000\n",
            "22100\n",
            "22200\n",
            "22300\n",
            "22400\n",
            "22500\n",
            "22600\n",
            "22700\n",
            "22800\n",
            "22900\n",
            "23000\n",
            "Wrong path: /content/drive/Shareddrives/Capstone 2023/Data/MicrosoftSnakeAlgorithmProject/Snake_Images/FL_Snakes/WF8/IMG_7087.JPG\n",
            "23100\n",
            "23200\n"
          ]
        }
      ],
      "source": [
        "images = []\n",
        "counter2 = 0\n",
        "# read in each image as grayscale (each is a 2d array)\n",
        "for img in filenames:\n",
        "\n",
        "    image = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
        "    if image is None:\n",
        "      print('Wrong path:', img)\n",
        "    else:\n",
        "      images.append(cv2.resize(image, (512, 384), interpolation = cv2.INTER_AREA))\n",
        "      if \"Empty\" in root:\n",
        "        labels.append(0)\n",
        "      elif \"Snake\" in root:\n",
        "        labels.append(1)\n",
        "\n",
        "    counter2 += 1\n",
        "    if counter2 % 100 == 0: print(counter2)\n",
        "    # if counter2 > 100: break\n",
        "\n",
        "# for image files, create label based on path: 0 means empty, 1 means snake\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtHfow2kLDUG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "545e6409-95d2-4a0d-eb8e-d1a9a51b02a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23275\n",
            "23275\n"
          ]
        }
      ],
      "source": [
        "print(len(images))\n",
        "print(len(labels)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FARQyzqK8_8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "97dfe5f8-2a40-46db-c76d-28bfbea956cb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-838f2be40804>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/images_resized.pkl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
          ]
        }
      ],
      "source": [
        "# import pickle\n",
        "\n",
        "# filepath = \"/content/drive/MyDrive/images_resized.pkl\" \n",
        "# with open(filepath,  'wb') as f:\n",
        "#   pickle.dump(images, f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "filepath = \"/content/drive/MyDrive/images_resized.pkl\" \n",
        "\n",
        "with open(filepath, 'rb') as f:\n",
        "    images = pickle.load(f)"
      ],
      "metadata": {
        "id": "2kM6iHwba1cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(images)):\n",
        "  # print(images[i].shape)\n",
        "  if images[i].shape != (512, 384):\n",
        "    print(filenames[i])"
      ],
      "metadata": {
        "id": "7KkHgD_mmtxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW8PfiYqQzjB"
      },
      "source": [
        "## Image display\n",
        "Uncomment cell below if you want to see the pictures as loaded via opencv (cv2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAAgXJmoQzjC"
      },
      "outputs": [],
      "source": [
        "# # display image - will pop up in a separate window (seems to crash in colab)\n",
        "\n",
        "# cv2.namedWindow(\"image1\", cv2.WINDOW_NORMAL)\n",
        "# cv2.imshow(\"image1\", images[0])\n",
        "# cv2.waitKey()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7fZcPxaQzjD"
      },
      "source": [
        "## Data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "mCEkOs7KQzjD",
        "outputId": "2e8f5a83-1c92-4a9b-dbf1-00be35ab25ae"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-802caa6b1fec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# convert to numpy arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimage_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlabel_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "# convert to numpy arrays\n",
        "image_arr = np.array(images)\n",
        "label_arr = np.array(labels)\n",
        "print(image_arr.shape)\n",
        "print(label_arr.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75lr7ZZoQzjF"
      },
      "outputs": [],
      "source": [
        "# # scale data (currently broken) \n",
        "# scaler = sklearn.preprocessing.MinMaxScaler()\n",
        "# image_scaled = scaler.fit_transform(image_arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSqTwUHmQzjG"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0eYqXw_QzjG",
        "outputId": "242be5ca-3a10-42b5-c3c4-504b953f03a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(23275, 512)\n"
          ]
        }
      ],
      "source": [
        "# take colmean of each image to reduce features (for logistic regression)\n",
        "image_reshape = image_arr.mean(axis=2)\n",
        "print(image_reshape.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubbHC0cxQzjH"
      },
      "outputs": [],
      "source": [
        "# scale data \n",
        "scaler = sklearn.preprocessing.MinMaxScaler()\n",
        "image_scaled = scaler.fit_transform(image_reshape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrFneVINQzjH"
      },
      "outputs": [],
      "source": [
        "# split data\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    image_reshape, label_arr, test_size = 0.4, stratify = label_arr, shuffle = True, random_state = 27)\n",
        "\n",
        "x_val, x_test, y_val, y_test = train_test_split(\n",
        "    x_test, y_test, test_size = 0.75, stratify = y_test, shuffle = True, random_state = 27)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "0b9-iW3xQzjI",
        "outputId": "cd086339-d691-4295-fa27-e01aaa88814c"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-efb896f49baf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlog_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sag\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# fit model on train data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlog_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1555\u001b[0m                 \u001b[0;34m\"This solver needs samples of at least 2 classes\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m                 \u001b[0;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
          ]
        }
      ],
      "source": [
        "## initialize logistic regression model\n",
        "# sag: stochastic average gradient descent, chosen for speed\n",
        "log_model = sklearn.linear_model.LogisticRegression(solver = \"sag\", max_iter = 10000)\n",
        "# fit model on train data\n",
        "log_model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tW7WIkIWQzjI"
      },
      "outputs": [],
      "source": [
        "# plot confusion matrix\n",
        "metrics.ConfusionMatrixDisplay.from_estimator(log_model, x_test, y_test,  cmap = \"GnBu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyR_a47RQzjJ"
      },
      "outputs": [],
      "source": [
        "### model evaluation metrics \n",
        "predictions = log_model.predict(x_test)\n",
        "\n",
        "# (true positive + true negative)/total\n",
        "accuracy = sklearn.metrics.accuracy_score(y_test, predictions)\n",
        "print(accuracy)\n",
        "\n",
        "# true positive/(true positive + false positive)\n",
        "precision = sklearn.metrics.precision_score(y_test, predictions)\n",
        "print(precision)\n",
        "\n",
        "# true positive/(true positive + false negative) aka recall\n",
        "sensitivity = sklearn.metrics.recall_score(y_test, predictions)\n",
        "print(sensitivity)\n",
        "\n",
        "# true negative/(true negative + false positive)\n",
        "specificity = sklearn.metrics.recall_score(y_test, predictions, pos_label = 0)\n",
        "print(specificity)\n",
        "\n",
        "# 2 * (precision*recall)/(precision+recall)\n",
        "f1_score = 2*(precision*sensitivity)/(precision+sensitivity)\n",
        "print(f1_score)\n",
        "\n",
        "# no false positives means precision and specificity will be 100%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2pQYwfUQzjK"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iinTnX7MQzjK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIEXQQfMaDZv"
      },
      "outputs": [],
      "source": [
        "# resize images else will run out of memory\n",
        "image_resized = []\n",
        "for image in image_arr:\n",
        "  image_resized.append(cv2.resize(image, (0, 0), fx = 0.25, fy = 0.25, interpolation = cv2.INTER_AREA))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJII-YMhaqNY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "8b46520a-445b-4ad4-d2ec-0ec7aa2ea2bb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-37def1360492>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# convert resized list into np array and scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage_arr_resized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_resized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_arr_resized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'image_resized' is not defined"
          ]
        }
      ],
      "source": [
        "# convert resized list into np array and scale\n",
        "image_arr_resized = np.array(image_resized)\n",
        "print(image_arr_resized.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYxybXGpW_Fs"
      },
      "outputs": [],
      "source": [
        "# # display image - will pop up in a separate window (seems to crash in colab)\n",
        "\n",
        "# cv2.namedWindow(\"image\", cv2.WINDOW_NORMAL)\n",
        "# cv2.imshow(\"image\", image_arr_resized[0])\n",
        "# cv2.waitKey()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bol6ZXuW_Ft"
      },
      "outputs": [],
      "source": [
        "# # display image - will pop up in a separate window (seems to crash in colab)\n",
        "\n",
        "# cv2.namedWindow(\"image\", cv2.WINDOW_NORMAL)\n",
        "# cv2.imshow(\"image\", image_arr_resized[0])\n",
        "# cv2.waitKey()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-VNDC1eQzjK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "207bfc46-c1b2-43d8-c7f3-81a1e20f0725"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-f56293b9502c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# reshape for cnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage_arr_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_arr_resized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_arr_resized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_arr_resized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_arr_resized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlabel_arr_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_arr_resized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ],
      "source": [
        "# reshape for cnn\n",
        "image_arr_reshaped = image_arr_resized.reshape([image_arr_resized.shape[0], image_arr_resized.shape[1], image_arr_resized.shape[2], 1])\n",
        "label_arr_reshaped = label_arr.reshape([image_arr_resized.shape[0], 1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape for cnn\n",
        "image_arr_reshaped = image_arr.reshape([image_arr.shape[0], image_arr.shape[1], image_arr.shape[2], 1])\n",
        "label_arr_reshaped = label_arr.reshape([image_arr.shape[0], 1])"
      ],
      "metadata": {
        "id": "65sncMsLM9oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvfa5MltQzjL"
      },
      "outputs": [],
      "source": [
        "# split data: train is 1-test_size and val, test are equal in size\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    image_arr_reshaped, label_arr_reshaped, test_size = 0.4, stratify = label_arr_reshaped, shuffle = True, random_state = 27)\n",
        "\n",
        "x_val, x_test, y_val, y_test = train_test_split(\n",
        "    x_test, y_test, test_size = 0.75, stratify = y_test, shuffle = True, random_state = 27)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgZdWzWOQzjL"
      },
      "outputs": [],
      "source": [
        "# create model (stock from keras documentation for now)\n",
        "def build_model():\n",
        "\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_arr_resized.shape[1], image_arr_resized.shape[2], 1)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(10))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer = \"adam\", loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtUfDNDiQzjM"
      },
      "outputs": [],
      "source": [
        "# build the model\n",
        "cnn_model = build_model()\n",
        "\n",
        "# or load saved (see google drive models folder for download)\n",
        "# cnn_model = tf.keras.models.load_model(\"../Snakes-or-No-Snakes/cnn_v2/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umrpF-ZgQzjM"
      },
      "outputs": [],
      "source": [
        "# train the model\n",
        "cnn_fit = cnn_model.fit(x_train, y_train, epochs=7, \n",
        "                        validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRogoOfKW_Fu"
      },
      "outputs": [],
      "source": [
        "# get class predictions\n",
        "predictions_cnn = np.argmax(cnn_model.predict(x_test), axis = -1) \n",
        "print(predictions_cnn.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbfSNf6GW_Fu"
      },
      "outputs": [],
      "source": [
        "# plot confusion matrix\n",
        "metrics.ConfusionMatrixDisplay.from_predictions(y_test, predictions_cnn, cmap = \"GnBu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1g6lEvNW_Fv"
      },
      "outputs": [],
      "source": [
        "### model evaluation metrics \n",
        "\n",
        "# (true positive + true negative)/total\n",
        "accuracy = sklearn.metrics.accuracy_score(y_test, predictions_cnn)\n",
        "print(accuracy)\n",
        "\n",
        "# true positive/(true positive + false positive)\n",
        "precision = sklearn.metrics.precision_score(y_test, predictions_cnn)\n",
        "print(precision)\n",
        "\n",
        "# true positive/(true positive + false negative)\n",
        "sensitivity = sklearn.metrics.recall_score(y_test, predictions_cnn)\n",
        "print(sensitivity)\n",
        "\n",
        "# true negative/(true negative + false positive)\n",
        "specificity = sklearn.metrics.recall_score(y_test, predictions_cnn, pos_label = 0)\n",
        "print(specificity)\n",
        "\n",
        "# 2 * (precision*recall)/(precision+recall)\n",
        "f1_score = 2*(precision*sensitivity)/(precision+sensitivity)\n",
        "print(f1_score)\n",
        "\n",
        "# no false positives means precision and specificity will be 100%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yFGoM0BW_Fv"
      },
      "outputs": [],
      "source": [
        "# plot accuracy across epochs\n",
        "plt.plot(cnn_fit.history['accuracy'], label='accuracy')\n",
        "plt.plot(cnn_fit.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = cnn_model.evaluate(x_test,  y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUbLCUlVW_Fv"
      },
      "outputs": [],
      "source": [
        "# save model\n",
        "cnn_model.save('../Snakes-or-No-Snakes/cnn_v3')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}